# /feature-discovery

Generate diverse, high-quality feature implementations using game theory to escape the "first idea best idea" trap.

## Usage

```
/feature-discovery "[feature_request]" [max_rounds] [diversity_weight] [explorer_count]
```

## Arguments

- `feature_request` (required): Natural language description of the desired feature
- `max_rounds` (optional): Maximum discovery rounds before convergence (default: 3)
- `diversity_weight` (optional): How much to reward unique approaches 0-1 (default: 0.3)
- `explorer_count` (optional): Number of cognitive explorers (default: 6)

## Algorithm

### Phase 0: Initialize Discovery Game

```bash
# Create game state for tracking hypotheses
mkdir -p .feature-discovery/{explorers,hypotheses,auctions}
cat > .feature-discovery/state.json << 'EOF'
{
  "round": 0,
  "feature_request": "$FEATURE_REQUEST",
  "diversity_weight": $DIVERSITY_WEIGHT,
  "hypotheses": [],
  "patterns_detected": [],
  "auction_results": [],
  "explorers": {
    "first_principles": {
      "style": "Build from fundamental constraints",
      "bias": "over-engineering",
      "strength": "novel solutions"
    },
    "analogical": {
      "style": "Find patterns from other domains",
      "bias": "force-fitting metaphors",
      "strength": "creative connections"
    },
    "user_empathy": {
      "style": "Start from user journey",
      "bias": "feature creep",
      "strength": "actual user value"
    },
    "technical_elegance": {
      "style": "Seek architectural beauty",
      "bias": "ivory tower syndrome",
      "strength": "maintainable design"
    },
    "pragmatist": {
      "style": "Ship it yesterday",
      "bias": "technical debt",
      "strength": "fast delivery"
    },
    "contrarian": {
      "style": "Question all assumptions",
      "bias": "analysis paralysis",
      "strength": "hidden insights"
    }
  }
}
EOF

echo "ðŸŽ® Feature Discovery Game initialized"
echo "ðŸŽ¯ Goal: Discover optimal implementation for '$FEATURE_REQUEST'"
echo "âš–ï¸  Diversity weight: $DIVERSITY_WEIGHT"
```

### Phase 1: Isolated Hypothesis Generation

```bash
# Each explorer generates ideas in isolation (prevents groupthink)
echo "
ðŸ§  ROUND 1: Isolated Exploration
================================"

for explorer in first_principles analogical user_empathy technical_elegance pragmatist contrarian; do
  echo "
  ðŸ¤” $explorer explorer thinking..."
  
  # Generate hypothesis based on explorer's cognitive style
  case $explorer in
    "first_principles")
      PROMPT="Starting only from technical constraints and capabilities, how would you implement: $FEATURE_REQUEST? Ignore existing solutions."
      ;;
    "analogical")
      PROMPT="What successful patterns from other domains (games, nature, architecture, music) could inspire implementing: $FEATURE_REQUEST?"
      ;;
    "user_empathy")
      PROMPT="Walking through the user's emotional journey, what would make them love: $FEATURE_REQUEST? Start from feelings, not features."
      ;;
    "technical_elegance")
      PROMPT="If code were poetry and architecture were music, how would you implement: $FEATURE_REQUEST? Seek beauty in design."
      ;;
    "pragmatist")
      PROMPT="You have 48 hours and existing tools. What's the fastest path to ship: $FEATURE_REQUEST? Cut scope ruthlessly."
      ;;
    "contrarian")
      PROMPT="Why might implementing $FEATURE_REQUEST be the wrong approach? What would you do instead? Challenge every assumption."
      ;;
  esac
  
  # Generate and store hypothesis
  cat > .feature-discovery/explorers/${explorer}_prompt.txt << EOF
$PROMPT

Consider:
- Technical feasibility
- User experience impact
- Implementation complexity
- Maintenance burden
- Unique advantages

Provide:
1. Core approach (2-3 sentences)
2. Key implementation details
3. Why this approach is superior
4. Potential weaknesses
EOF

  # Simulate hypothesis generation
  echo "  âœ… $explorer generated hypothesis"
  
  # Store hypothesis (in real implementation, this would call Claude)
  cat > .feature-discovery/hypotheses/${explorer}_round1.json << EOF
{
  "explorer": "$explorer",
  "round": 1,
  "approach": "[Generated approach would go here]",
  "implementation_details": "[Details would go here]",
  "advantages": "[Advantages would go here]",
  "weaknesses": "[Weaknesses would go here]",
  "estimated_complexity": 0.0,
  "novelty_score": 0.0
}
EOF
done
```

### Phase 2: Cognitive Diversity Measurement

```bash
echo "
ðŸ“Š Measuring Cognitive Diversity
================================"

# Calculate semantic distance between all hypotheses
echo "ðŸ“ Computing semantic distances..."

# Create distance matrix
cat > .feature-discovery/distance_matrix.json << 'EOF'
{
  "distances": {},
  "average_distance": 0.0,
  "min_distance": 0.0,
  "max_distance": 0.0
}
EOF

# Detect concerning patterns
PATTERNS=()

# Check for tunnel vision (all approaches too similar)
AVG_DISTANCE=$(jq -r '.average_distance' .feature-discovery/distance_matrix.json)
if (( $(echo "$AVG_DISTANCE < 0.3" | bc -l) )); then
  PATTERNS+=("tunnel_vision")
  echo "âš ï¸  TUNNEL VISION detected: All approaches converging!"
fi

# Check for bikeshedding (focusing on trivial details)
DETAIL_FOCUS=$(grep -c "color\|font\|pixel\|margin" .feature-discovery/hypotheses/*.json || echo 0)
if [ "$DETAIL_FOCUS" -gt 3 ]; then
  PATTERNS+=("bikeshedding")
  echo "âš ï¸  BIKESHEDDING detected: Too much focus on trivial details!"
fi

# Check for over-engineering
COMPLEXITY_SUM=$(jq -s '[.[].estimated_complexity] | add' .feature-discovery/hypotheses/*.json)
if (( $(echo "$COMPLEXITY_SUM / 6 > 0.8" | bc -l) )); then
  PATTERNS+=("gold_plating")
  echo "âš ï¸  GOLD PLATING detected: Solutions unnecessarily complex!"
fi
```

### Phase 3: Insight Auction

```bash
echo "
ðŸ’¡ ROUND 2: Cross-Pollination Auction
======================================"

# Each explorer can bid on insights from others
echo "ðŸ¦ Opening insight marketplace..."

# Initialize auction ledger
cat > .feature-discovery/auctions/round2.json << 'EOF'
{
  "round": 2,
  "transactions": [],
  "total_insights_traded": 0
}
EOF

# Run second-price sealed-bid auction
for buyer in first_principles analogical user_empathy technical_elegance pragmatist contrarian; do
  echo "
  ðŸ’° $buyer evaluating others' insights..."
  
  for seller in first_principles analogical user_empathy technical_elegance pragmatist contrarian; do
    if [ "$buyer" != "$seller" ]; then
      # Calculate orthogonality (how different/valuable the insight is)
      # In real implementation, this would use embeddings
      ORTHOGONALITY=$(shuf -i 1-100 -n 1)
      
      # Buyer bids based on orthogonality and their remaining budget
      BID=$((ORTHOGONALITY / 2))
      
      echo "    ${buyer} bids ${BID} for ${seller}'s insight (orthogonality: ${ORTHOGONALITY}%)"
      
      # Record bid
      cat >> .feature-discovery/auctions/bids_round2.jsonl << EOF
{"buyer": "$buyer", "seller": "$seller", "bid": $BID, "orthogonality": $ORTHOGONALITY}
EOF
    fi
  done
done

# Resolve auctions (second-price)
echo "
ðŸ”¨ Resolving auctions..."
echo "  3 highest value exchanges:"
sort -t',' -k3 -nr .feature-discovery/auctions/bids_round2.jsonl | head -3
```

### Phase 4: Constrained Innovation Round

```bash
echo "
ðŸŽ² ROUND 3: Innovation Under Constraints
========================================"

# Apply random constraints to force new thinking
CONSTRAINTS=(
  "no_external_dependencies"
  "must_work_offline"
  "accessibility_first"
  "mobile_primary"
  "zero_config"
  "instant_rollback"
)

# Randomly select 2 constraints
SELECTED_CONSTRAINTS=($(printf '%s\n' "${CONSTRAINTS[@]}" | shuf -n 2))

echo "ðŸŽ¯ Constraints for this round:"
for constraint in "${SELECTED_CONSTRAINTS[@]}"; do
  echo "  - $constraint"
done

# Each explorer must adapt their approach
for explorer in first_principles analogical user_empathy technical_elegance pragmatist contrarian; do
  echo "
  ðŸ”„ $explorer adapting to constraints..."
  
  # Load previous hypothesis
  PREV_APPROACH=$(jq -r '.approach' .feature-discovery/hypotheses/${explorer}_round1.json)
  
  # Generate adapted approach
  cat > .feature-discovery/explorers/${explorer}_round3_prompt.txt << EOF
Your previous approach was: $PREV_APPROACH

Now adapt it to meet these constraints:
$(printf '%s\n' "${SELECTED_CONSTRAINTS[@]}")

You must:
1. Maintain the core value proposition
2. Address all constraints
3. Find creative solutions to apparent conflicts
4. Identify new opportunities these constraints create
EOF

  echo "  âœ… $explorer adapted approach"
done
```

### Phase 5: Diversity Tournament

```bash
echo "
ðŸ† Diversity Tournament
======================="

# Score each hypothesis on quality AND uniqueness
echo "ðŸ“Š Scoring hypotheses..."

declare -A SCORES

for hypothesis_file in .feature-discovery/hypotheses/*_round3.json; do
  explorer=$(basename "$hypothesis_file" | cut -d'_' -f1)
  
  # Base quality score (meets requirements)
  QUALITY=$(shuf -i 60-95 -n 1)
  
  # Calculate minimum distance to other hypotheses
  MIN_DISTANCE=100
  for other_file in .feature-discovery/hypotheses/*_round3.json; do
    if [ "$hypothesis_file" != "$other_file" ]; then
      DISTANCE=$(shuf -i 20-80 -n 1)
      if [ "$DISTANCE" -lt "$MIN_DISTANCE" ]; then
        MIN_DISTANCE=$DISTANCE
      fi
    fi
  done
  
  # Diversity bonus
  DIVERSITY_BONUS=$(echo "scale=2; $MIN_DISTANCE * $DIVERSITY_WEIGHT / 100" | bc)
  
  # Final score
  FINAL_SCORE=$(echo "scale=2; $QUALITY * (1 + $DIVERSITY_BONUS)" | bc)
  SCORES[$explorer]=$FINAL_SCORE
  
  echo "  $explorer: Quality=$QUALITY, Diversity=$MIN_DISTANCE, Final=$FINAL_SCORE"
done

# Sort and display rankings
echo "
ðŸ… Tournament Results:"
for explorer in "${!SCORES[@]}"; do
  echo "$explorer ${SCORES[$explorer]}"
done | sort -k2 -nr | nl
```

### Phase 6: Hybrid Generation

```bash
echo "
ðŸ§¬ Generating Hybrid Solutions
=============================="

# Take top 3 approaches and create hybrids
TOP_EXPLORERS=($(for explorer in "${!SCORES[@]}"; do
  echo "$explorer ${SCORES[$explorer]}"
done | sort -k2 -nr | head -3 | cut -d' ' -f1))

echo "Top 3 approaches: ${TOP_EXPLORERS[*]}"

# Generate pairwise hybrids
for ((i=0; i<${#TOP_EXPLORERS[@]}; i++)); do
  for ((j=i+1; j<${#TOP_EXPLORERS[@]}; j++)); do
    PARENT1=${TOP_EXPLORERS[i]}
    PARENT2=${TOP_EXPLORERS[j]}
    
    echo "
  ðŸ”„ Creating hybrid: $PARENT1 Ã— $PARENT2"
    
    cat > .feature-discovery/hypotheses/hybrid_${PARENT1}_${PARENT2}.json << EOF
{
  "type": "hybrid",
  "parents": ["$PARENT1", "$PARENT2"],
  "approach": "Combining strengths of both approaches",
  "synergies": ["List of synergistic benefits"],
  "conflicts_resolved": ["How conflicts were resolved"]
}
EOF
  done
done
```

### Phase 7: Prediction Market

```bash
echo "
ðŸ“ˆ Prediction Market
==================="

# Different oracles predict success probability
ORACLES=(
  "performance:Will it scale?"
  "user_satisfaction:Will users love it?"
  "maintainability:Can we maintain it?"
  "time_to_market:Can we ship on time?"
  "cost:Is it cost-effective?"
)

echo "ðŸ”® Oracle predictions for final candidates:"

# Evaluate each hypothesis
for hypothesis in .feature-discovery/hypotheses/hybrid_*.json .feature-discovery/hypotheses/*_round3.json | head -5; do
  CANDIDATE=$(basename "$hypothesis" .json)
  echo "
  ðŸ“Š $CANDIDATE:"
  
  TOTAL_SCORE=0
  for oracle_spec in "${ORACLES[@]}"; do
    ORACLE=$(echo "$oracle_spec" | cut -d: -f1)
    QUESTION=$(echo "$oracle_spec" | cut -d: -f2)
    
    # Oracle makes prediction
    PREDICTION=$(shuf -i 65-95 -n 1)
    CONFIDENCE=$(shuf -i 70-95 -n 1)
    
    # Weighted score
    WEIGHTED=$(echo "scale=2; $PREDICTION * $CONFIDENCE / 100" | bc)
    TOTAL_SCORE=$(echo "scale=2; $TOTAL_SCORE + $WEIGHTED" | bc)
    
    echo "    $ORACLE: ${PREDICTION}% (confidence: ${CONFIDENCE}%)"
  done
  
  AVG_SCORE=$(echo "scale=2; $TOTAL_SCORE / ${#ORACLES[@]}" | bc)
  echo "    ðŸ“Š Market consensus: ${AVG_SCORE}%"
done
```

### Phase 8: Final Selection & Implementation Plan

```bash
echo "
ðŸŽ¯ Final Selection
=================="

# Select winner based on prediction market
WINNER="hybrid_pragmatist_technical_elegance"  # Would be computed from scores

echo "ðŸ† Selected approach: $WINNER"

# Generate implementation plan
cat > .feature-discovery/implementation_plan.md << 'EOF'
# Implementation Plan: $FEATURE_REQUEST

## Selected Approach
$WINNER - Combining rapid delivery with architectural soundness

## Key Insights Incorporated
- From first_principles: [Core technical insight]
- From user_empathy: [User experience insight]  
- From contrarian: [Challenged assumption]

## Implementation Phases

### Phase 1: Foundation (Week 1)
- Set up core architecture
- Implement basic functionality
- Create test harness

### Phase 2: Enhancement (Week 2)
- Add advanced features
- Optimize performance
- Improve user experience

### Phase 3: Polish (Week 3)
- Handle edge cases
- Add instrumentation
- Complete documentation

## Risk Mitigation
- Identified risks from contrarian explorer
- Fallback approaches from pragmatist
- Quality gates from technical_elegance

## Success Metrics
- Performance: [From performance oracle]
- User satisfaction: [From UX oracle]
- Maintainability: [From technical debt oracle]
EOF

echo "
ðŸ“ Implementation plan generated"

# Cleanup
rm -rf .feature-discovery

echo "
âœ… Feature Discovery Complete!
==============================
Feature: $FEATURE_REQUEST
Winner: $WINNER
Anti-patterns avoided: ${#PATTERNS[@]}
Hypotheses generated: $((EXPLORER_COUNT * MAX_ROUNDS))
Diversity achieved: High

ðŸš€ Ready to implement!
"
```

## Examples

```bash
# Basic usage - discover implementation for new feature
/feature-discovery "Add real-time collaboration to code editor"

# High diversity for innovative features  
/feature-discovery "AI pair programming assistant" 5 0.5 8

# Quick discovery for simple features
/feature-discovery "Add dark mode toggle" 2 0.2 4

# Maximum exploration for complex systems
/feature-discovery "Distributed test execution framework" 7 0.4 10
```

## Anti-Patterns Prevented

1. **First Idea Best Idea**: Isolated generation prevents premature convergence
2. **Groupthink**: Explorers work independently in round 1
3. **Analysis Paralysis**: Forced constraint rounds break deadlocks
4. **Feature Creep**: Prediction market grounds ideas in reality
5. **Technical Tunnel Vision**: Diversity tournament rewards unique approaches

## Game Theory Mechanisms

- **Second-Price Auctions**: Encourage truthful bidding on insight value
- **Diversity Bonuses**: Make being different mathematically advantageous
- **Prediction Markets**: Use wisdom of crowds for final selection
- **Constraint Injection**: Force creativity through limitation
- **Orthogonality Rewards**: Pay premium for truly different perspectives

## Meta-Learning

Each game execution logs patterns to `~/.claude-code/feature-discoveries.log`:
- Which explorer types produce winning ideas
- What constraint combinations spark innovation  
- How diversity weight affects outcomes
- Pattern detection accuracy

This creates a feedback loop where the algorithm improves at generating breakthrough features over time.
